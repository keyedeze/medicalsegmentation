{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "468df23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print('CUDA available:', torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba5b457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda:0\n",
      "\n",
      "If you use this tool please cite: https://pubs.rsna.org/doi/10.1148/ryai.230024\n",
      "\n",
      "TotalSegmentator sends anonymous usage statistics. If you want to disable it check the documentation.\n",
      "Downloading model for Task 291 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 234M/234M [00:02<00:00, 115MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extracting...\n",
      "Downloading model for Task 292 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 234M/234M [00:02<00:00, 114MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extracting...\n",
      "Downloading model for Task 293 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 234M/234M [00:01<00:00, 118MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extracting...\n",
      "Downloading model for Task 294 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 234M/234M [00:01<00:00, 117MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extracting...\n",
      "Downloading model for Task 295 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 234M/234M [00:01<00:00, 120MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extracting...\n",
      "tmp_dir: /tmp/nnunet_tmp_lb6vnkqy\n",
      "Resampling...\n",
      "  from shape (122, 101, 112) to shape (244, 202, 224)\n",
      "  Resampled in 2.79s\n",
      "Predicting part 1 of 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/research/projects/Kayacan/python_envs/TotalSeg_env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 cases in the source folder\n",
      "I am processing 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
      "There are 1 cases that I would like to predict\n",
      "\n",
      "Predicting s01:\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:13<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling and export\n",
      "done with s01\n",
      "Predicting part 2 of 5 ...\n",
      "There are 1 cases in the source folder\n",
      "I am processing 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
      "There are 1 cases that I would like to predict\n",
      "\n",
      "Predicting s01:\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 60.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling and export\n",
      "done with s01\n",
      "Predicting part 3 of 5 ...\n",
      "There are 1 cases in the source folder\n",
      "I am processing 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
      "There are 1 cases that I would like to predict\n",
      "\n",
      "Predicting s01:\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 62.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling and export\n",
      "done with s01\n",
      "Predicting part 4 of 5 ...\n",
      "There are 1 cases in the source folder\n",
      "I am processing 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
      "There are 1 cases that I would like to predict\n",
      "\n",
      "Predicting s01:\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 51.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling and export\n",
      "done with s01\n",
      "Predicting part 5 of 5 ...\n",
      "There are 1 cases in the source folder\n",
      "I am processing 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
      "There are 1 cases that I would like to predict\n",
      "\n",
      "Predicting s01:\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 64.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling and export\n",
      "done with s01\n",
      "  Predicted in 95.56s\n",
      "Resampling...\n",
      "  back to original shape: (122, 101, 112)\n",
      "Undoing canonical...\n",
      "Saving segmentations...\n",
      "  Saved in 0.01s\n",
      "Solutions: segmentations\n"
     ]
    }
   ],
   "source": [
    "from totalsegmentator.python_api import totalsegmentator\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"example_ct.nii.gz\"\n",
    "    output_file = \"segmentations\"\n",
    "\n",
    "    totalsegmentator(\n",
    "        input=input_file,\n",
    "        output=output_file,\n",
    "        fast=False, \n",
    "        preview = False,\n",
    "        task=\"total\", \n",
    "        ml=True, \n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    print(f\"Solutions: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TotalSeg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
